# ğŸŒŸ Estimate Multimodal Transformer Observation Difference

ğŸš€ **Multimodal Transformer Model** | **Image Observation Comparison**

### ğŸ”¥ Project Overview

Welcome to the **Estimate Multimodal Transformer Observation Difference** project! This project focuses on utilizing a multimodal transformer to generate **observations from two images** and **calculate a numerical difference** between the observations. The images are from the **BDD100K dataset**, and we use **Fuyu-8B model** to compare the observations and generate high-level metrics.

---

### ğŸ¯ **Objective**

Our goal is to:
- Analyze **two images** using the multimodal transformer.
- Generate **numerical difference scores** based on observation disagreements.
- Optionally compute **semantic distance** for more advanced comparisons.

---

## ğŸ› ï¸ **Features**

- ğŸ§  **Multimodal Transformer Model (Fuyu-8B)**
- ğŸ–¼ï¸ **BDD100K Dataset**
- ğŸ“Š **Numerical Difference Scoring**
- ğŸŒ€ **Cosine Similarity for Semantic Distance (Optional)**
- ğŸš€ **GPU Acceleration** for faster training and inference.

---

## âš™ï¸ **Installation**

 Clone the repository:

   ```bash
   git clone https://github.com/username/multimodal-transformer.git
   cd multimodal-transformer

"Transforming images, one comparison at a time!"
