# ðŸŒŸ Estimate Multimodal Transformer Observation Difference

ðŸš€ **Multimodal Transformer Model** | **Image Observation Comparison**

### ðŸ”¥ Project Overview

Welcome to the **Estimate Multimodal Transformer Observation Difference** project! This project focuses on utilizing a multimodal transformer to generate **observations from two images** and **calculate a numerical difference** between the observations. The images are from the **BDD100K dataset**, and we use **Fuyu-8B model** to compare the observations and generate high-level metrics.

---

### ðŸŽ¯ **Objective**

Our goal is to:
- Analyze **two images** using the multimodal transformer.
- Generate **numerical difference scores** based on observation disagreements.
- Optionally compute **semantic distance** for more advanced comparisons.

---

## ðŸ› ï¸ **Features**

- ðŸ§  **Multimodal Transformer Model (Fuyu-8B)**
- ðŸ–¼ï¸ **BDD100K Dataset**
- ðŸ“Š **Numerical Difference Scoring**
- ðŸŒ€ **Cosine Similarity for Semantic Distance (Optional)**
- ðŸš€ **GPU Acceleration** for faster training and inference.

---

## âš™ï¸ **Installation**

 Clone the repository:

   ```bash
   git clone https://github.com/username/multimodal-transformer.git
   cd multimodal-transformer

---

## ðŸ’¬ **Contact**

Feel free to reach out for any queries or collaboration ideas!

> "Transforming images, one comparison at a time!"


